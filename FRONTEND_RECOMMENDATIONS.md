# Zalecenia dotyczƒÖce struktury danych dla Swift i Next.js

## üì± Swift ‚Üí Next.js ‚Üí Backend Python

### Struktura danych wymagana przez backend

Backend Python oczekuje nastƒôpujƒÖcej struktury JSON:

```typescript
interface VolumeEstimationRequest {
  background: {
    depth: string;        // Base64 encoded depth map (uint16 array)
    timestamp: string;   // ISO 8601 timestamp
  };
  object: {
    depth: string;        // Base64 encoded depth map (uint16 array)
    mask: string;         // JSON string z tablicƒÖ punkt√≥w [{"x": number, "y": number}, ...]
    timestamp: string;    // ISO 8601 timestamp
  };
  camera_intrinsics: {
    fx: number;          // Horizontal focal length
    fy: number;          // Vertical focal length
    cx: number;          // Principal point x
    cy: number;          // Principal point y
    width: number;       // Image width in pixels
    height: number;      // Image height in pixels
  };
  metadata: {
    device_model: string; // Np. "Intel RealSense D435i"
  };
}
```

---

## üçé Zalecenia dla Swift (iOS)

### 1. Struktura danych do wysy≈Çki do Next.js

Zdefiniuj strukturƒô danych w Swift:

```swift
import Foundation

// MARK: - Request Structures
struct VolumeEstimationRequest: Codable {
    let background: ImageData
    let object: ObjectData
    let cameraIntrinsics: CameraIntrinsics
    let metadata: Metadata

    enum CodingKeys: String, CodingKey {
        case background
        case object
        case cameraIntrinsics = "camera_intrinsics"
        case metadata
    }
}

struct ImageData: Codable {
    let depth: String      // Base64 encoded depth map
    let timestamp: String  // ISO 8601 format
}

struct ObjectData: Codable {
    let depth: String      // Base64 encoded depth map
    let mask: String       // JSON string with points array
    let timestamp: String
}

struct CameraIntrinsics: Codable {
    let fx: Double
    let fy: Double
    let cx: Double
    let cy: Double
    let width: Int
    let height: Int
}

struct Metadata: Codable {
    let deviceModel: String

    enum CodingKeys: String, CodingKey {
        case deviceModel = "device_model"
    }
}
```

### 2. Przygotowanie danych depth map

```swift
import UIKit
import AVFoundation

extension UIImage {
    /// Konwertuje depth map do base64 string
    func encodeDepthToBase64() -> String? {
        guard let ciImage = CIImage(image: self),
              let depthData = ciImage.properties[kCGImagePropertyDepthData as String] as? [String: Any],
              let depthMap = depthData["DepthMap"] as? Data else {
            return nil
        }
        return depthMap.base64EncodedString()
    }
}

// Alternatywnie, je≈õli u≈ºywasz AVDepthData:
func encodeAVDepthToBase64(depthData: AVDepthData) -> String? {
    let depthMap = depthData.depthDataMap
    let width = CVPixelBufferGetWidth(depthMap)
    let height = CVPixelBufferGetHeight(depthMap)

    CVPixelBufferLockBaseAddress(depthMap, .readOnly)
    defer { CVPixelBufferUnlockBaseAddress(depthMap, .readOnly) }

    guard let baseAddress = CVPixelBufferGetBaseAddress(depthMap) else {
        return nil
    }

    let bytesPerRow = CVPixelBufferGetBytesPerRow(depthMap)
    let data = Data(bytes: baseAddress, count: bytesPerRow * height)

    return data.base64EncodedString()
}
```

### 3. Przygotowanie maski jako JSON string

```swift
struct MaskPoint: Codable {
    let x: Double
    let y: Double
}

func createMaskJSONString(points: [CGPoint]) -> String? {
    let maskPoints = points.map { point in
        MaskPoint(x: Double(point.x), y: Double(point.y))
    }

    guard let jsonData = try? JSONEncoder().encode(maskPoints),
          let jsonString = String(data: jsonData, encoding: .utf8) else {
        return nil
    }

    return jsonString
}
```

### 4. Wysy≈Çanie danych do Next.js API

```swift
import Foundation

class VolumeEstimationService {
    let nextJSBaseURL: String = "https://your-nextjs-app.com/api" // Zmie≈Ñ na sw√≥j URL

    func sendVolumeEstimation(
        backgroundDepth: String,
        backgroundTimestamp: Date,
        objectDepth: String,
        objectMask: [CGPoint],
        objectTimestamp: Date,
        cameraIntrinsics: CameraIntrinsics,
        deviceModel: String,
        completion: @escaping (Result<VolumeEstimationResponse, Error>) -> Void
    ) {
        // Przygotuj maskƒô jako JSON string
        guard let maskJSON = createMaskJSONString(points: objectMask) else {
            completion(.failure(NSError(domain: "MaskEncodingError", code: -1)))
            return
        }

        // Przygotuj request
        let request = VolumeEstimationRequest(
            background: ImageData(
                depth: backgroundDepth,
                timestamp: ISO8601DateFormatter().string(from: backgroundTimestamp)
            ),
            object: ObjectData(
                depth: objectDepth,
                mask: maskJSON,
                timestamp: ISO8601DateFormatter().string(from: objectTimestamp)
            ),
            cameraIntrinsics: cameraIntrinsics,
            metadata: Metadata(deviceModel: deviceModel)
        )

        // Konwertuj do JSON
        guard let jsonData = try? JSONEncoder().encode(request),
              let jsonString = String(data: jsonData, encoding: .utf8),
              let url = URL(string: "\(nextJSBaseURL)/volume-estimation") else {
            completion(.failure(NSError(domain: "RequestEncodingError", code: -1)))
            return
        }

        // Przygotuj HTTP request
        var urlRequest = URLRequest(url: url)
        urlRequest.httpMethod = "POST"
        urlRequest.setValue("application/json", forHTTPHeaderField: "Content-Type")
        urlRequest.httpBody = jsonData

        // Wy≈õlij request
        URLSession.shared.dataTask(with: urlRequest) { data, response, error in
            if let error = error {
                completion(.failure(error))
                return
            }

            guard let data = data else {
                completion(.failure(NSError(domain: "NoDataError", code: -1)))
                return
            }

            do {
                let response = try JSONDecoder().decode(VolumeEstimationResponse.self, from: data)
                completion(.success(response))
            } catch {
                completion(.failure(error))
            }
        }.resume()
    }
}
```

### 5. Przyk≈Çad u≈ºycia w Swift

```swift
let service = VolumeEstimationService()

let cameraIntrinsics = CameraIntrinsics(
    fx: 607.18,
    fy: 606.77,
    cx: 329.46,
    cy: 242.86,
    width: 640,
    height: 480
)

let maskPoints: [CGPoint] = [
    CGPoint(x: 188.0, y: 75.0),
    CGPoint(x: 224.0, y: 58.0),
    // ... wiƒôcej punkt√≥w
]

service.sendVolumeEstimation(
    backgroundDepth: backgroundDepthBase64,
    backgroundTimestamp: Date(),
    objectDepth: objectDepthBase64,
    objectMask: maskPoints,
    objectTimestamp: Date(),
    cameraIntrinsics: cameraIntrinsics,
    deviceModel: "Intel RealSense D435i"
) { result in
    switch result {
    case .success(let response):
        print("Success! Request ID: \(response.requestId)")
    case .failure(let error):
        print("Error: \(error.localizedDescription)")
    }
}
```

---

## ‚öõÔ∏è Zalecenia dla Next.js

### 1. API Route do przyjƒôcia danych z Swift

Utw√≥rz plik `pages/api/volume-estimation/index.ts` (lub `app/api/volume-estimation/route.ts` dla App Router):

```typescript
import type { NextApiRequest, NextApiResponse } from 'next';

interface VolumeEstimationRequest {
  background: {
    depth: string;
    timestamp: string;
  };
  object: {
    depth: string;
    mask: string; // JSON string
    timestamp: string;
  };
  camera_intrinsics: {
    fx: number;
    fy: number;
    cx: number;
    cy: number;
    width: number;
    height: number;
  };
  metadata: {
    device_model: string;
  };
}

interface VolumeEstimationResponse {
  message: string;
  request_id: number;
  status: string;
}

export default async function handler(
  req: NextApiRequest,
  res: NextApiResponse<VolumeEstimationResponse | { error: string }>
) {
  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' });
  }

  try {
    // Walidacja danych
    const data: VolumeEstimationRequest = req.body;

    // Sprawd≈∫ wymagane pola
    if (!data.background?.depth || !data.background?.timestamp) {
      return res.status(400).json({ error: 'Missing background data' });
    }

    if (!data.object?.depth || !data.object?.mask || !data.object?.timestamp) {
      return res.status(400).json({ error: 'Missing object data' });
    }

    if (!data.camera_intrinsics || !data.metadata) {
      return res.status(400).json({ error: 'Missing camera intrinsics or metadata' });
    }

    // Walidacja mask - sprawd≈∫ czy to poprawny JSON
    try {
      const maskPoints = JSON.parse(data.object.mask);
      if (!Array.isArray(maskPoints) || maskPoints.length === 0) {
        return res.status(400).json({ error: 'Invalid mask format' });
      }
    } catch {
      return res.status(400).json({ error: 'Invalid mask JSON format' });
    }

    // Wy≈õlij do backendu Python
    const backendUrl = process.env.BACKEND_URL || 'https://your-backend-url.com';
    const response = await fetch(`${backendUrl}/enqueue-volume-estimation`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(data),
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error('Backend error:', errorText);
      return res.status(response.status).json({
        error: `Backend error: ${response.statusText}`
      });
    }

    const result: VolumeEstimationResponse = await response.json();
    return res.status(200).json(result);

  } catch (error) {
    console.error('Error processing request:', error);
    return res.status(500).json({
      error: 'Internal server error'
    });
  }
}
```

### 2. App Router (Next.js 13+)

Je≈õli u≈ºywasz App Router, utw√≥rz `app/api/volume-estimation/route.ts`:

```typescript
import { NextRequest, NextResponse } from 'next/server';

export async function POST(request: NextRequest) {
  try {
    const data = await request.json();

    // Walidacja danych (tak jak powy≈ºej)
    if (!data.background?.depth || !data.background?.timestamp) {
      return NextResponse.json(
        { error: 'Missing background data' },
        { status: 400 }
      );
    }

    if (!data.object?.depth || !data.object?.mask || !data.object?.timestamp) {
      return NextResponse.json(
        { error: 'Missing object data' },
        { status: 400 }
      );
    }

    // Walidacja mask
    try {
      const maskPoints = JSON.parse(data.object.mask);
      if (!Array.isArray(maskPoints) || maskPoints.length === 0) {
        return NextResponse.json(
          { error: 'Invalid mask format' },
          { status: 400 }
        );
      }
    } catch {
      return NextResponse.json(
        { error: 'Invalid mask JSON format' },
        { status: 400 }
      );
    }

    // Wy≈õlij do backendu Python
    const backendUrl = process.env.BACKEND_URL || 'https://your-backend-url.com';
    const response = await fetch(`${backendUrl}/enqueue-volume-estimation`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(data),
    });

    if (!response.ok) {
      const errorText = await response.text();
      return NextResponse.json(
        { error: `Backend error: ${response.statusText}` },
        { status: response.status }
      );
    }

    const result = await response.json();
    return NextResponse.json(result);

  } catch (error) {
    console.error('Error processing request:', error);
    return NextResponse.json(
      { error: 'Internal server error' },
      { status: 500 }
    );
  }
}
```

### 3. TypeScript types dla Next.js

Utw√≥rz plik `types/volume-estimation.ts`:

```typescript
export interface VolumeEstimationRequest {
  background: {
    depth: string;
    timestamp: string;
  };
  object: {
    depth: string;
    mask: string; // JSON string with points array
    timestamp: string;
  };
  camera_intrinsics: {
    fx: number;
    fy: number;
    cx: number;
    cy: number;
    width: number;
    height: number;
  };
  metadata: {
    device_model: string;
  };
}

export interface VolumeEstimationResponse {
  message: string;
  request_id: number;
  status: string;
}

export interface MaskPoint {
  x: number;
  y: number;
}
```

### 4. Funkcja pomocnicza do walidacji

Utw√≥rz `utils/validation.ts`:

```typescript
import { VolumeEstimationRequest, MaskPoint } from '@/types/volume-estimation';

export function validateVolumeEstimationRequest(
  data: any
): data is VolumeEstimationRequest {
  // Sprawd≈∫ strukturƒô
  if (!data || typeof data !== 'object') {
    return false;
  }

  // Background
  if (!data.background?.depth || !data.background?.timestamp) {
    return false;
  }

  // Object
  if (!data.object?.depth || !data.object?.mask || !data.object?.timestamp) {
    return false;
  }

  // Camera intrinsics
  const ci = data.camera_intrinsics;
  if (!ci ||
      typeof ci.fx !== 'number' ||
      typeof ci.fy !== 'number' ||
      typeof ci.cx !== 'number' ||
      typeof ci.cy !== 'number' ||
      typeof ci.width !== 'number' ||
      typeof ci.height !== 'number') {
    return false;
  }

  // Metadata
  if (!data.metadata?.device_model || typeof data.metadata.device_model !== 'string') {
    return false;
  }

  // Walidacja mask
  try {
    const maskPoints: MaskPoint[] = JSON.parse(data.object.mask);
    if (!Array.isArray(maskPoints) || maskPoints.length === 0) {
      return false;
    }

    // Sprawd≈∫ strukturƒô punkt√≥w
    for (const point of maskPoints) {
      if (typeof point.x !== 'number' || typeof point.y !== 'number') {
        return false;
      }
    }
  } catch {
    return false;
  }

  return true;
}
```

### 5. Konfiguracja ≈õrodowiska

Dodaj do `.env.local`:

```env
BACKEND_URL=https://breva-ai-dvf4dcgrcag9fvff.polandcentral-01.azurewebsites.net
```

### 6. Przyk≈Çad u≈ºycia z frontendu Next.js

```typescript
// components/VolumeEstimationForm.tsx
'use client';

import { useState } from 'react';

export default function VolumeEstimationForm() {
  const [loading, setLoading] = useState(false);
  const [result, setResult] = useState<any>(null);

  const handleSubmit = async (data: VolumeEstimationRequest) => {
    setLoading(true);
    try {
      const response = await fetch('/api/volume-estimation', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(data),
      });

      if (!response.ok) {
        throw new Error('Failed to send request');
      }

      const result = await response.json();
      setResult(result);
    } catch (error) {
      console.error('Error:', error);
    } finally {
      setLoading(false);
    }
  };

  // ... reszta komponentu
}
```

---

## üîë Kluczowe punkty do zapamiƒôtania

### ‚úÖ Co jest WYMAGANE:

1. **Background**: `depth` (base64), `timestamp` (ISO 8601)
2. **Object**: `depth` (base64), `mask` (JSON string), `timestamp` (ISO 8601)
3. **Camera Intrinsics**: wszystkie 6 warto≈õci numeryczne
4. **Metadata**: `device_model` jako string

### ‚ùå Co NIE jest ju≈º u≈ºywane:

- **Pole `rgb`** - zosta≈Ço usuniƒôte z API
- **Mask jako base64** - mask musi byƒá JSON string z tablicƒÖ punkt√≥w

### üìù Format mask:

```json
"[{\"x\": 188.0, \"y\": 75.0}, {\"x\": 224.0, \"y\": 58.0}, ...]"
```

### ‚ö†Ô∏è Wa≈ºne uwagi:

1. **Timestamp**: U≈ºywaj formatu ISO 8601: `"2025-10-29T21:04:01.974618"`
2. **Depth maps**: MuszƒÖ byƒá zakodowane jako base64 z raw uint16 array
3. **Mask points**: Wsp√≥≈Çrzƒôdne muszƒÖ byƒá liczbami (nie stringami)
4. **CORS**: Upewnij siƒô, ≈ºe backend Python ma skonfigurowane CORS dla domeny Next.js

---

## üß™ Testowanie

### Test z Swift:

```swift
// Sprawd≈∫ czy dane sƒÖ poprawnie zakodowane
print("Background depth length: \(backgroundDepth.count)")
print("Object depth length: \(objectDepth.count)")
print("Mask JSON: \(maskJSON)")
```

### Test z Next.js:

```typescript
// W API route, przed wys≈Çaniem do backendu:
console.log('Received data:', {
  background: {
    depthLength: data.background.depth.length,
    timestamp: data.background.timestamp
  },
  object: {
    depthLength: data.object.depth.length,
    maskLength: data.object.mask.length,
    timestamp: data.object.timestamp
  },
  cameraIntrinsics: data.camera_intrinsics,
  metadata: data.metadata
});
```
